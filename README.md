# AgenticRagLearning

What is embedding?

Embedding enables machine learning models to find similar objects i.e. they allow models to learn complex patterns and relationships in the data. For instance, in natural language processing (NLP), words with similar meanings will have similar embeddings to easily understand the relationships between different words and categories instead of just analysing each word in isolation thus, generate more coherent and contextually relevant responses to user prompts and questions.
Embeddings are not only used for text data, but can also be applied to a wide range of data types, including images, graphs, and more. Depending on the type of data you’re working with, different types of embeddings can be used.

What is Vector?

ML models cannot interpret information intelligibly in their raw format and require low-dimensional numerical data as input. Therefore, it is necessary to convert the data into a numerical format.
ML models use neural network embeddings to convert real-word information into numerical representations called vectors. Vectors are numerical values that represent information in a multi-dimensional array. They help ML models to find similarities among sparsely distributed items. 

“dad”=[0.1548,0.4848,…,1.864] 
 “mom”=[0.8785,0.8974,…,2.794] 

